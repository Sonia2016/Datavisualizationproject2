# Visualization Project 2
Text and Geospatial visualization


## Data Processing
In this project, students will work on the texts extracted from news/blogs and classified into 4 categories: people names, locations, organizations, and miscellaneous. Each entry also contains the published time/date of the article/blog.
Students are provided 2 datasets: The Wikinews data (roughly 3.3M) contains 11,267 articles and the Huffington Post data (roughly 29.4M) contains 75,293 political blogs. Students are required to demonstrate their web applications on both datasets.

### First meeting - October 19
#### Check the problem definition
For each of bullet we check our understanding and check to each other
We had some question related to relationship between terms that figured out is the one blog (one row in the data)
The problem is that how should we work with wordle and tagcrowd? What is the input and output?
If we just put the one column it shows the 50 top for that column but if we have two column it is not 50 top for each of them. How can we figure out the relationship of different columns?
Answer:


### Second meeting - October 24
#### Frequency of the data for each colum
We decided to do 50 top frequency of each category data until Wednesday.
As this time, we figured out heap is the best one to restore the data because of time complexity but it can be change if we find better one.
##### Action List
- Sonia is working on "Person" and "Miscellanous"
- Brindivani is working on "Location"
- Arun is working on "Organization"

